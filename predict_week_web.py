import streamlit as st
import pandas as pd
from sqlalchemy import create_engine
import urllib
from tqdm import tqdm
import lightgbm as lgb
import numpy as np

# Streamlit ì•±ì˜ ì œëª© ì„¤ì •
st.set_page_config(page_title="ì œí’ˆ ì¶œê³ ëŸ‰ ì£¼ì°¨ë³„ ì˜ˆì¸¡", layout="wide")
st.title("ğŸ“¦ ì œí’ˆ ì¶œê³ ëŸ‰ ì£¼ì°¨ë³„ ì˜ˆì¸¡ ì‹œìŠ¤í…œ")

st.markdown("""
ì´ ì•±ì€ ì œí’ˆë³„ ì£¼ì°¨ë³„ ì¶œê³ ëŸ‰ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê³¼ê±° ì¶œê³  ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™€ ëª¨ë¸ì„ í•™ìŠµí•˜ê³ ,
ì§€ì •ëœ ê¸°ê°„ ë™ì•ˆì˜ ë¯¸ë˜ ì¶œê³ ëŸ‰ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
""")

# --- DB ì—°ê²° ì„¤ì • (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼) ---
server = 'localhost'
database = 'SPTEST1'
driver = 'ODBC Driver 17 for SQL Server'
params = urllib.parse.quote_plus(
    f"DRIVER={driver};SERVER={server};DATABASE={database};Trusted_Connection=yes;"
)

# SQLAlchemy ì—”ì§„ì€ í•œ ë²ˆë§Œ ìƒì„±í•˜ëŠ” ê²ƒì´ íš¨ìœ¨ì ì…ë‹ˆë‹¤.
@st.cache_resource
def get_db_engine():
    """ë°ì´í„°ë² ì´ìŠ¤ ì—”ì§„ì„ ìºì‹±í•˜ì—¬ ì—¬ëŸ¬ ë²ˆ ìƒì„±í•˜ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤."""
    try:
        engine = create_engine(f"mssql+pyodbc:///?odbc_connect={params}")
        # ì—°ê²° í…ŒìŠ¤íŠ¸ (ì„ íƒ ì‚¬í•­)
        with engine.connect() as connection:
            connection.execute(pd.text('SELECT 1'))
        st.success("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ! âœ…")
        return engine
    except Exception as e:
        st.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e} âŒ")
        st.warning("DB ì—°ê²° ë¬¸ìì—´, ì„œë²„ ìƒíƒœ, ë°ì´í„°ë² ì´ìŠ¤/í…Œì´ë¸” ì´ë¦„, ODBC ë“œë¼ì´ë²„ ì„¤ì¹˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return None

engine = get_db_engine()

# --- ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ë° ì „ì²˜ë¦¬ (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼) ---
@st.cache_data(show_spinner="ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê³  ì „ì²˜ë¦¬ ì¤‘...") # ë°ì´í„°ë¥¼ ìºì‹±í•˜ì—¬ ì•± ì¬ì‹¤í–‰ ì‹œ ë‹¤ì‹œ ë¡œë“œí•˜ì§€ ì•Šë„ë¡ í•¨
def load_and_preprocess_data(engine):
    if engine is None:
        return pd.DataFrame(), pd.DataFrame(), "DB ì—°ê²° ì‹¤íŒ¨"

    try:
        df = pd.read_sql("SELECT * FROM Tì¶œê³ ", engine)
        
        if 'ì¶œê³ ì¼ì' not in df.columns:
            return pd.DataFrame(), pd.DataFrame(), "'ì¶œê³ ì¼ì' ì»¬ëŸ¼ì´ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤."

        df['ì¶œê³ ì¼ì'] = pd.to_datetime(df['ì¶œê³ ì¼ì'], errors='coerce')
        df = df.dropna(subset=['ì¶œê³ ì¼ì'])

        if len(df) == 0:
            return pd.DataFrame(), pd.DataFrame(), "'ì¶œê³ ì¼ì' ë³€í™˜ í›„ ëª¨ë“  ë°ì´í„°ê°€ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤."

        df['ì¶œê³ ë…„ë„'] = df['ì¶œê³ ì¼ì'].dt.isocalendar().year.astype(int)
        df['ì¶œê³ ì£¼ì°¨'] = df['ì¶œê³ ì¼ì'].dt.isocalendar().week.astype(int)
        df['ì¶œê³ ìš”ì¼'] = (df['ì¶œê³ ì¼ì'].dt.weekday + 1).astype(int)
        df['ì›”'] = df['ì¶œê³ ì¼ì'].dt.month
        df['ë¶„ê¸°'] = df['ì¶œê³ ì¼ì'].dt.quarter
        df['ì¼'] = df['ì¶œê³ ì¼ì'].dt.day 
        df['ì£¼ì°¨_ì‹œì‘ì¼'] = df['ì¶œê³ ì¼ì'] - pd.to_timedelta(df['ì¶œê³ ìš”ì¼'] - 1, unit='D')

        weekly_df = df.groupby(['ì œí’ˆì½”ë“œ', 'ì¶œê³ ë…„ë„', 'ì¶œê³ ì£¼ì°¨', 'ì£¼ì°¨_ì‹œì‘ì¼', 'ì›”', 'ë¶„ê¸°', 'ì¶œê³ ìš”ì¼'])['í™•ì •ìˆ˜ëŸ‰'].sum().reset_index()
        weekly_df = weekly_df.sort_values(by=['ì œí’ˆì½”ë“œ', 'ì¶œê³ ë…„ë„', 'ì¶œê³ ì£¼ì°¨']).copy()
        weekly_df['ì£¼ì°¨ìˆœì„œ'] = weekly_df.groupby('ì œí’ˆì½”ë“œ').cumcount()

        weekly_df['í™•ì •ìˆ˜ëŸ‰_ì§ì „ì£¼'] = weekly_df.groupby('ì œí’ˆì½”ë“œ')['í™•ì •ìˆ˜ëŸ‰'].shift(1)
        weekly_df['í™•ì •ìˆ˜ëŸ‰_2ì£¼ì „'] = weekly_df.groupby('ì œí’ˆì½”ë“œ')['í™•ì •ìˆ˜ëŸ‰'].shift(2)
        weekly_df['í™•ì •ìˆ˜ëŸ‰_1ë…„ì „'] = weekly_df.groupby('ì œí’ˆì½”ë“œ')['í™•ì •ìˆ˜ëŸ‰'].shift(52)
        weekly_df['í™•ì •ìˆ˜ëŸ‰_4ì£¼í‰ê· '] = weekly_df.groupby('ì œí’ˆì½”ë“œ')['í™•ì •ìˆ˜ëŸ‰'].rolling(window=4, min_periods=1).mean().reset_index(level=0, drop=True)
        weekly_df.fillna(0, inplace=True)

        if len(weekly_df) == 0:
            return pd.DataFrame(), pd.DataFrame(), "ì£¼ì°¨ë³„ ì§‘ê³„ í›„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        st.success(f"ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ ì™„ë£Œ! ì´ {len(weekly_df)} ì£¼ì°¨ë³„ ë°ì´í„° ë¡œë“œ.")
        return df, weekly_df, None

    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e} âŒ")
        return pd.DataFrame(), pd.DataFrame(), "ë°ì´í„° ì²˜ë¦¬ ì˜¤ë¥˜"

# ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
df_raw, weekly_df, data_load_error = load_and_preprocess_data(engine)

if data_load_error:
    st.error(data_load_error)
    st.stop() # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì•± ì‹¤í–‰ ì¤‘ì§€

# --- ì˜ˆì¸¡ ë¡œì§ (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼) ---
@st.cache_data(show_spinner="ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘...")
def run_prediction(weekly_df_data, start_date, end_date):
    results = []
    codes = weekly_df_data['ì œí’ˆì½”ë“œ'].unique()
    
    st.info(f"ì´ {len(codes)}ê°œì˜ ì œí’ˆì— ëŒ€í•´ ì˜ˆì¸¡ì„ ì‹œì‘í•©ë‹ˆë‹¤.")

    predict_dates_range = []
    current_date = start_date
    while current_date <= end_date:
        predict_dates_range.append(current_date)
        current_date += pd.Timedelta(weeks=1)

    num_forecast_weeks = len(predict_dates_range)

    features = [
        'ì£¼ì°¨ìˆœì„œ', 'ì¶œê³ ë…„ë„', 'ì¶œê³ ì£¼ì°¨', 'ì›”', 'ë¶„ê¸°', 'ì¶œê³ ìš”ì¼', 
        'í™•ì •ìˆ˜ëŸ‰_ì§ì „ì£¼', 'í™•ì •ìˆ˜ëŸ‰_2ì£¼ì „', 'í™•ì •ìˆ˜ëŸ‰_1ë…„ì „', 'í™•ì •ìˆ˜ëŸ‰_4ì£¼í‰ê· '
    ]

    progress_bar = st.progress(0)
    for idx, code in enumerate(tqdm(codes, desc="ì œí’ˆë³„ ì˜ˆì¸¡ ì§„í–‰ ì¤‘")):
        sub = weekly_df_data[weekly_df_data['ì œí’ˆì½”ë“œ'] == code].copy()

        if len(sub) < 60:
            # st.warning(f"ì œí’ˆì½”ë“œ {code}: í•™ìŠµ ë°ì´í„°ê°€ 60ì£¼ ë¯¸ë§Œì´ë¯€ë¡œ ì˜ˆì¸¡ì—ì„œ ì œì™¸ë©ë‹ˆë‹¤.")
            continue

        X_train = sub[features]
        y_train = sub['í™•ì •ìˆ˜ëŸ‰']

        if X_train.isnull().all().all():
            # st.warning(f"ì œí’ˆì½”ë“œ {code}: í›ˆë ¨ ë°ì´í„°ê°€ ëª¨ë‘ Nullì´ë¯€ë¡œ ì˜ˆì¸¡ì—ì„œ ì œì™¸ë©ë‹ˆë‹¤.")
            continue

        model = lgb.LGBMRegressor(random_state=42, verbose=-1) # verbose=-1 ë¡œ ê²½ê³  ë©”ì‹œì§€ ìˆ¨ê¹€
        try:
            model.fit(X_train, y_train)
        except lgb.basic.LightGBMError as e:
            # st.warning(f"ì œí’ˆì½”ë“œ {code}: ëª¨ë¸ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ({e}). ì˜ˆì¸¡ì—ì„œ ì œì™¸ë©ë‹ˆë‹¤.")
            continue

        last_observed_row = sub.iloc[-1]
        
        predicted_lag1 = last_observed_row['í™•ì •ìˆ˜ëŸ‰']
        predicted_lag2 = last_observed_row['í™•ì •ìˆ˜ëŸ‰_ì§ì „ì£¼'] 
        
        def get_lag_year_value(product_code, year, week, weekly_df_data_inner):
            prev_year_data = weekly_df_data_inner[
                (weekly_df_data_inner['ì œí’ˆì½”ë“œ'] == product_code) &
                (weekly_df_data_inner['ì¶œê³ ë…„ë„'] == year - 1) &
                (weekly_df_data_inner['ì¶œê³ ì£¼ì°¨'] == week)      
            ]
            if not prev_year_data.empty:
                return prev_year_data['í™•ì •ìˆ˜ëŸ‰'].iloc[0]
            return 0 

        recent_quantities_for_rolling = sub['í™•ì •ìˆ˜ëŸ‰'].tail(4).tolist()

        current_product_forecast_list = []

        for j in range(num_forecast_weeks):
            current_date_for_prediction = predict_dates_range[j]
            
            last_train_week_date = sub['ì£¼ì°¨_ì‹œì‘ì¼'].max()
            # ë§ˆì§€ë§‰ í›ˆë ¨ ë°ì´í„°ì˜ ì£¼ì°¨ìˆœì„œê°€ ì˜ˆì¸¡ ì‹œì‘ ë‚ ì§œë³´ë‹¤ ë¯¸ë˜ì¼ ê²½ìš°ë¥¼ ë°©ì§€
            # ì˜ˆì¸¡ ì‹œì‘ ë‚ ì§œê°€ í›ˆë ¨ ë°ì´í„°ì˜ ë§ˆì§€ë§‰ ë‚ ì§œë³´ë‹¤ í•­ìƒ ë¯¸ë˜ì—¬ì•¼ í•¨
            if last_train_week_date is pd.NaT or current_date_for_prediction < last_train_week_date:
                # ì´ ê²½ìš°ëŠ” ì˜ˆì¸¡í•  ë°ì´í„°ê°€ ì•„ë‹ˆë¯€ë¡œ ìŠ¤í‚µí•˜ê±°ë‚˜ ì ì ˆíˆ ì²˜ë¦¬
                # ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœíˆ ìŠ¤í‚µí•©ë‹ˆë‹¤.
                continue 

            last_train_week_order = sub[sub['ì£¼ì°¨_ì‹œì‘ì¼'] == last_train_week_date]['ì£¼ì°¨ìˆœì„œ'].iloc[0]

            time_diff_in_weeks = (current_date_for_prediction - last_train_week_date).days // 7
            future_order_for_model = last_train_week_order + time_diff_in_weeks


            lag_year_value = get_lag_year_value(code, current_date_for_prediction.year, current_date_for_prediction.isocalendar().week, weekly_df_data)
            
            current_rolling_mean = np.mean(recent_quantities_for_rolling[-4:]) if len(recent_quantities_for_rolling) >= 1 else 0


            future_features_dict = {
                'ì£¼ì°¨ìˆœì„œ': future_order_for_model,
                'ì¶œê³ ë…„ë„': current_date_for_prediction.year,
                'ì¶œê³ ì£¼ì°¨': current_date_for_prediction.isocalendar().week,
                'ì›”': current_date_for_prediction.month,
                'ë¶„ê¸°': current_date_for_prediction.quarter,
                'ì¶œê³ ìš”ì¼': current_date_for_prediction.weekday() + 1, 
                'í™•ì •ìˆ˜ëŸ‰_ì§ì „ì£¼': predicted_lag1,
                'í™•ì •ìˆ˜ëŸ‰_2ì£¼ì „': predicted_lag2,
                'í™•ì •ìˆ˜ëŸ‰_1ë…„ì „': lag_year_value,
                'í™•ì •ìˆ˜ëŸ‰_4ì£¼í‰ê· ': current_rolling_mean
            }
            
            future_df_for_prediction = pd.DataFrame([future_features_dict], columns=features)
            
            predicted_quantity = model.predict(future_df_for_prediction)[0]
            predicted_quantity = max(0, int(round(predicted_quantity)))

            predicted_lag2 = predicted_lag1
            predicted_lag1 = predicted_quantity
            
            recent_quantities_for_rolling.append(predicted_quantity)
            if len(recent_quantities_for_rolling) > 4:
                recent_quantities_for_rolling.pop(0)

            year_str = current_date_for_prediction.strftime('%Yë…„')
            month_str = current_date_for_prediction.strftime('%mì›”')
            
            first_day_of_month = current_date_for_prediction.replace(day=1)
            first_iso_week_of_month = first_day_of_month.isocalendar().week
            
            current_iso_week = current_date_for_prediction.isocalendar().week
            week_of_month = current_iso_week - first_iso_week_of_month + 1
            if week_of_month <= 0:
                week_of_month = 1
            
            week_str = f'{int(week_of_month)}ì£¼ì°¨'

            current_product_forecast_list.append({
                'ì œí’ˆì½”ë“œ': code,
                'ì˜ˆì¸¡_ê¸°ê°„': f'{year_str} {month_str} {week_str}',
                'ì˜ˆì¸¡ìˆ˜ëŸ‰': predicted_quantity
            })
        
        results.extend(current_product_forecast_list)
        progress_bar.progress((idx + 1) / len(codes))
    
    return results

# --- Streamlit UI êµ¬ì„± ---
st.header("ì˜ˆì¸¡ ì„¤ì •")

# ì˜ˆì¸¡ ê¸°ê°„ ì…ë ¥
col1, col2 = st.columns(2)
with col1:
    default_start_date = pd.to_datetime('2025-08-04').date() # ì˜¤ëŠ˜ ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë³€ê²½ (í˜„ì¬ 2025ë…„ 7ì›” 16ì¼ì´ë¯€ë¡œ ë¯¸ë˜ ë‚ ì§œë¡œ ì„¤ì •)
    st.date_input("ì˜ˆì¸¡ ì‹œì‘ ë‚ ì§œë¥¼ ì„ íƒí•˜ì„¸ìš”:", value=default_start_date, key="start_date")
with col2:
    default_end_date = pd.to_datetime('2025-10-27').date() # ì˜ˆì¸¡ ê¸°ê°„ì„ ì¡°ì ˆ
    st.date_input("ì˜ˆì¸¡ ì¢…ë£Œ ë‚ ì§œë¥¼ ì„ íƒí•˜ì„¸ìš”:", value=default_end_date, key="end_date")

start_date_input = st.session_state.start_date
end_date_input = st.session_state.end_date

# ì œí’ˆ ì„ íƒ (ì˜µì…˜)
# product_codes = ['ì „ì²´'] + sorted(weekly_df['ì œí’ˆì½”ë“œ'].unique().tolist())
# selected_product_code = st.selectbox("íŠ¹ì • ì œí’ˆ ì½”ë“œë¥¼ ì„ íƒí•˜ì„¸ìš” (ì„ íƒ ì‚¬í•­):", product_codes)


if st.button("ì˜ˆì¸¡ ì‹¤í–‰"):
    if engine is None:
        st.error("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì´ ì„¤ì •ë˜ì§€ ì•Šì•„ ì˜ˆì¸¡ì„ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    elif weekly_df.empty:
        st.error("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê±°ë‚˜ ì „ì²˜ë¦¬í•˜ëŠ” ì¤‘ì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì˜ˆì¸¡ì„ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    elif start_date_input >= end_date_input:
        st.error("ì˜ˆì¸¡ ì‹œì‘ ë‚ ì§œëŠ” ì˜ˆì¸¡ ì¢…ë£Œ ë‚ ì§œë³´ë‹¤ ë¹¨ë¼ì•¼ í•©ë‹ˆë‹¤.")
    else:
        st.subheader("ì˜ˆì¸¡ ê²°ê³¼")
        # ì‹¤ì œ ì˜ˆì¸¡ í•¨ìˆ˜ í˜¸ì¶œ
        # ì„ íƒëœ ì œí’ˆ ì½”ë“œ í•„í„°ë§
        # if selected_product_code == 'ì „ì²´':
        #     filtered_weekly_df = weekly_df
        # else:
        #     filtered_weekly_df = weekly_df[weekly_df['ì œí’ˆì½”ë“œ'] == selected_product_code]
        
        # if filtered_weekly_df.empty:
        #     st.warning("ì„ íƒëœ ì œí’ˆ ì½”ë“œì— ëŒ€í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        # else:
        forecast_results = run_prediction(weekly_df, 
                                          pd.to_datetime(start_date_input), 
                                          pd.to_datetime(end_date_input))

        if forecast_results:
            forecast_df = pd.DataFrame(forecast_results)
            forecast_df['ì˜ˆì¸¡_ê¸°ê°„_ì›”_ì‹œì‘ì¼'] = forecast_df['ì˜ˆì¸¡_ê¸°ê°„'].apply(lambda x: pd.to_datetime(x.split(' ')[0] + x.split(' ')[1], format='%Yë…„%mì›”'))
            forecast_df['ì˜ˆì¸¡_ê¸°ê°„_ì£¼ì°¨ë²ˆí˜¸'] = forecast_df['ì˜ˆì¸¡_ê¸°ê°„'].apply(lambda x: int(x.split(' ')[2].replace('ì£¼ì°¨', '')))
            
            final_forecast_df = forecast_df.sort_values(by=['ì œí’ˆì½”ë“œ', 'ì˜ˆì¸¡_ê¸°ê°„_ì›”_ì‹œì‘ì¼', 'ì˜ˆì¸¡_ê¸°ê°„_ì£¼ì°¨ë²ˆí˜¸']).drop(columns=['ì˜ˆì¸¡_ê¸°ê°„_ì›”_ì‹œì‘ì¼', 'ì˜ˆì¸¡_ê¸°ê°„_ì£¼ì°¨ë²ˆí˜¸'])
            
            st.dataframe(final_forecast_df, use_container_width=True) # ë°ì´í„°í”„ë ˆì„ì„ ì›¹ì— í‘œì‹œ
            
            # ì˜ˆì¸¡ ê²°ê³¼ë¥¼ CSVë¡œ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆë„ë¡ ë²„íŠ¼ ì¶”ê°€
            csv = final_forecast_df.to_csv(index=False).encode('utf-8-sig') # í•œê¸€ ê¹¨ì§ ë°©ì§€ë¥¼ ìœ„í•´ utf-8-sig
            st.download_button(
                label="ì˜ˆì¸¡ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
                data=csv,
                file_name="predicted_shipment_weekly.csv",
                mime="text/csv",
            )
        else:
            st.warning("ì˜ˆì¸¡ ê°€ëŠ¥í•œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. (ë°ì´í„° ë¶€ì¡± ë˜ëŠ” ì „ì²˜ë¦¬ ì˜¤ë¥˜ë¡œ ì¸í•´ ì˜ˆì¸¡ì´ ìˆ˜í–‰ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.)")

st.markdown("---")
st.markdown("Made with â¤ï¸ by Your Name/Company Name")